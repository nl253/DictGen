#!/usr/bin/python3
from pathlib import Path
import sys
import re
from collections import Counter
from argparse import ArgumentParser
from urllib.request import urlopen

# - choices -- A container of values that should be allowed. If not None,
# after a command-line argument has been converted to the appropriate
# type, an exception will be raised if it is not a member of this
# collection.

parser = ArgumentParser(description='Generate a dictionary from a file (and other tool).')
parser.add_argument('sources', nargs='+', type=str)
parser.add_argument('-f', '--frequency',
                    action='store_true',
                    help='Add [FREQUENCY] count to entries ')
parser.add_argument('-l', '--length',
                    nargs='?',
                    type=str,
                    default="3",
                    help='specify the minimul [LENGTH] of entries')
parser.add_argument('-n', '--number',
                    nargs='?',
                    type=int,
                    default="1000",
                    help='specify the [NUMBER] of entries')
parser.add_argument('-p', '--pattern', nargs='?',
                    type=str,
                    default="alpha",
                    choices=['lower', 'upper', 'alnum', 'alpha'],
                    help='specify the [CASE] of entries')
parser.add_argument('-m', '--maximum',
                    nargs='?',
                    type=str,
                    default="",
                    help='specify the [MAXIMUM] for all entries')
parser.add_argument('-s', '--stopWordsFilter',
                    action='store_true',
                    help='don\'t show entries classed as common by NLTK.')

args = parser.parse_args()

text = ""


# SOURCES
for i in args.sources:
    source = Path(i)
    if source.exists() and source.is_file():
        try:
            with source.open(encoding='utf-8') as f:
                text += f.read()
        except Exception as e:
            print(e)
    elif bool(re.search('https?:.*', i)):
        if not 'BeautifulSoup' in dir():
            from bs4 import BeautifulSoup
        try:
            text += BeautifulSoup(urlopen(i, timeout=10).content, 'html.parser').text
        except:
            pass


if args.pattern == 'lower':
    pat = '[a-z]'
elif args.pattern == 'upper':
    pat = '[A-Z]'
elif args.pattern == 'alpha':
    pat = '[A-Za-z]'
elif args.pattern == 'alnum':
    pat = '[A-Za-z0-9]'

pattern = re.compile(pat + "{" + args.length + "," + args.maximum + "}(?=[- \t\n\.,;:!?])")

matchesDict = Counter(pattern.findall(text))

# --stopWordsFilter
#
if args.stopWordsFilter and 'nlkt' in map(str, sys.modules):
    from nltk.corpus import stopwords
    SW = stopwords.words('english')
    for entry in matchesDict:
        if entry in SW:
            matchesDict.pop(i)

result = [i[0] for i in matchesDict.most_common(args.number)] if not args.frequency else matchesDict.most_common(args.number)


if args.frequency:
    for i in range(len(result)):
        print(result[i][0], result[i][1])
else:
    for i in result:
        print(i)


# vim: ft=python
