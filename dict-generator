#!/usr/bin/python
from pathlib import Path
import re
from nltk.corpus import stopwords
from bs4 import BeautifulSoup
from requests import get
from collections import Counter
from argparse import ArgumentParser

def validate_url(potentialURL):
    if re.match('https?:.*', potentialURL):
        return True
    return False

parser = ArgumentParser(description='Generate a dictionary from a file (and other tool).')
parser.add_argument('sources', nargs='+', type=str)
parser.add_argument('-o', '--output', nargs='?', type=str, default="",
                    help='The [OUTPUT FILE] where the DICT should be written')
parser.add_argument('-f', '--frequency', action='store_true',
                    help='Add [FREQUENCY] count to entries ')
parser.add_argument('-l', '--length', nargs='?', type=str, default="2",
                    help='specify the minimul [LENGTH] of entries')
parser.add_argument('-n', '--number', nargs='?', type=str, default="1000",
                    help='specify the [NUMBER] of entries')
parser.add_argument('-p', '--pattern', nargs='?', type=str, default="upperlower",
                    help='specify the [CASE] of entries [upperlower, lower, upper, alnum] :: DEFAULT : upperlower')
parser.add_argument('-m', '--maximum', nargs='?', type=str, default="",
                    help='specify the [MAXIMUM] for all entries')
parser.add_argument('-s', '--stopWordsFilter', action='store_true',
                    help='don\'t show entries classed as common by NLTK.')

args = parser.parse_args()

text = ""

# SOURCES
#
for i in args.sources:
    if Path(i).exists() and Path(i).is_file():
        text += Path(i).read_text()
    elif not Path(i).exists() and not Path(i).is_file() and validate_url(i):
        text += BeautifulSoup(get(i).content, 'html.parser').text

# --pattern
#
# --length
#
# --maximum
#
if args.pattern == 'upperlower':
    pat = '\w'
elif args.pattern == 'lower':
    pat = '[a-z]'
elif args.pattern == 'upper':
    pat = '[A-Z]'
elif args.pattern == 'alnum':
    pat = '\S'

pattern = re.compile(pat + "{" + args.length + "," + args.maximum + "}", flags=re.MULTILINE)

matchesDict = Counter(pattern.findall(text))


# --stopWordsFilter
#
if args.stopWordsFilter:
    SW = stopwords.words('english')
    for entry in matchesDict:
        if entry in SW:
            matchesDict.pop(i)

# --frequency
#
if not args.frequency:
    outputFormat = " str(word + '\\n') "
elif args.frequency:
    outputFormat = " word + ' ' + str(frequency) + '\\n' "

exec("result = ''.join([" + outputFormat + "for word, frequency in Counter("
    + "matchesDict).most_common(" + args.number + ")])")

# --output
#
if not args.output:
    print(result)
else:
    if not Path(args.output).exists():
        Path(args.output).touch()
    Path(args.output).write_text(result)

